---
title: "Data Science Capstone Data Analysis"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
author: "Kyla Mazzotta"
# date: "today"
date: "`r Sys.Date()`"
---

```{r include = FALSE}
#install.packages("jsonlite")
library(jsonlite)
#install.packages("dplyr")
library(dplyr)
#install.packages("purrr")
library(purrr)
#install.packages("stringr")
library(stringr)
#install.packages("readr")
library(readr)
#install.packages("corrplot")
library(corrplot)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("MASS")
library("MASS")
#install.packages("car")
library("car")
#install.packages("broom")
library(broom)
```


# Data
- A dataset containing web scraped race results from the UTMB website
- Originally a json object, was then loaded before preprocessing
```{r}
utmb_data <- fromJSON("utmb-race-data-raw.json", flatten=TRUE)
```

```{r include = FALSE}
str(utmb_data[[1]])
```



## Data Preprocessing
- Prior research shows that ultra marathons tend to be dominated by American and European athletes as there is little to no monetary incentive to perform well, a key factor differentiating marathon participants from ultra marathon participants.
- The main focus for this statistical analysis was therefore to isolate races that occurred in the United States to reduce potential variability in results across finish times with differen participant demographics country-wise.
- The UTMB race results were then filtered to only contain data on races located in the US
```{r}
us_races <- utmb_data[
  sapply(utmb_data, function(x) {
    grepl("United States|USA|US$", x$`City / Country`, ignore.case = TRUE)
  })
]
```

- The dataset of US races was then converted into a data frame to prepare for exploratory data analysis (EDA)
- The original dataset contained information on the number of participants in. each age 4-year age group. Since the there is little variation in finish times with such small age groups, they were consolidated into three bins:
  - Under 35
  - 35 - 59
  - 60 and older
- Each age group bin was also adjusted to reoprt the percentage of athletes in each age group as opposed to number as the races vary in size and participant breakdowns.
```{r}
us_df <- imap_dfr(us_races, ~{
  results <- .x$Results
  total_age <- sum(unlist(.x$Age))
  tibble(
    race_id        = .y,
    city_country   = .x$`City / Country`,
    date           = .x$Date,
    distance       = .x$Distance,
    elevation_gain = .x$`Elevation Gain`,
    n_participants = length(results),
    mean_time_hrs      = mean(results, na.rm = TRUE),
    median_time_hrs    = median(results, na.rm = TRUE),
    sd_time            = sd(results, na.rm = TRUE),
    min_time_hrs       = min(results, na.rm = TRUE),
    max_time_hrs       = max(results, na.rm = TRUE),
    pct_women      = .x$Sex$Women / sum(unlist(.x$Sex)),
    pct_age_u35     = sum(unlist(.x$Age[c("U18", "U20", "20-34")]), na.rm = TRUE) / total_age,
    pct_age_35_59     = sum(unlist(.x$Age[c("35-39", "40-44", "45-49", "50-54", "55-59")]), na.rm = TRUE) / total_age,
    pct_age_60_plus = sum(unlist(.x$Age[c("60-64", "65-69", "70-74", "75-79", "80+")]), na.rm = TRUE) / total_age
  )
})
```
- Since races also vary in number of participants, it was important to determine what the smallest acceptable race size would be to control for potential extreme race times.
- Total numbers if participants varied from 17 to 1842, therefore it was important to eliminate some of the smaller races from the data.
```{r}
# min number of participants
min(us_df$n_participants, na.rm = TRUE)
# 17

# max number of participants
max(us_df$n_participants, na.rm = TRUE)
# 1842

# distribution
summary(us_df$n_participants)
```
- The 25th percentile was calculated to be races with 85 participants, therefore it was decided that only races with 85 or more participants would be analyzed as these races were sufficiently large enough while not eliminating too many data points
```{r}
us_df <- us_df %>% filter(n_participants >= 85)
```
- Distance and elevation variables were also converted from character strings to variables for analysis
```{r}
colnames(us_df)[4] <- "distance_km"
colnames(us_df)[5] <- "elevation_gain_m"

us_df <- us_df %>%
  mutate(
    distance_km = parse_number(distance_km),
    elevation_gain_m = parse_number(elevation_gain_m)
  )
```

will also only use distances greater than or equal to 50km
```{r}
us_df <- us_df %>% filter(distance_km >= 50)
```

center distance and elevation gain values
```{r}
mean_distance_km <- mean(us_df$distance_km)
mean_elevation_m <- mean(us_df$elevation_gain_m)

us_df$distance_km <- us_df$distance_km - mean_distance_km
us_df$elevation_gain_m <- us_df$elevation_gain_m - mean_elevation_m
```

# reminder that now all distance and elevation values are centered
# distance baseline = 85.0581
# elevation baseline = 2564.2234


##### EDA

making a correlation matrix to see which factors should be included in regression
remove pct_u35 to fix correlation issues (perfect multicollinearity)
```{r}
correlation_matrix <- us_df %>% dplyr::select(distance_km, elevation_gain_m, pct_women, pct_age_35_59, pct_age_60_plus)

corrplot(cor(correlation_matrix))
```

### Preliminary scatterplots for analysis

- scatterplot of distance and elevation to see if linear relationship (maybe non-linear)

- scatterplot indicates potential quadratic relationship between distance and mean finish time
```{r}
ggplot(us_df, aes(x = distance_km, y = mean_time_hrs)) +
      geom_point()

ggplot(us_df, aes(x = elevation_gain_m, y = mean_time_hrs)) +
      geom_point()
```




### Regression

prelim regression with just main effects
remember that we are using pct_u35 as the base so it is not included in models (to avoid perfect multicollinearity)
```{r}
prelim_regression <- lm(mean_time_hrs ~ distance_km + I(distance_km^2) + elevation_gain_m +
                          pct_women + pct_age_35_59 + pct_age_60_plus, data = us_df)
summary(prelim_regression)

par(mfrow = c(1,2))
plot(prelim_regression, which=1, main="prelim model", pch=20)
plot(prelim_regression, which=2, main="prelim model", pch=20)
```
##### Using log regression as main model for robustness
due to data not appearing to be normally distributing, going to attempt logistic regression mmodel
```{r}
us_df <- us_df %>%
  mutate(log_mean_time = log(mean_time_hrs))
```

parsimonious model
```{r}
log_regression <- lm(log_mean_time ~ distance_km + I(distance_km^2) + elevation_gain_m +
                          pct_women + pct_age_35_59 + pct_age_60_plus, data = us_df)

summary(log_regression)

par(mfrow = c(1,2))
plot(log_regression, which=1, main="prelim model", pch=20)
plot(log_regression, which=2, main="prelim model", pch=20)
```


regressions with full model (interaction and higher order) adding only terms that are hypothesized to be significant and relevant
```{r}
full_log_regression <- lm(log_mean_time ~ distance_km + I(distance_km^2) + elevation_gain_m +
                          pct_women + pct_age_35_59 + pct_age_60_plus +
                          distance_km*elevation_gain_m + distance_km*pct_women +
                          elevation_gain_m*pct_women, data = us_df)
summary(full_log_regression)

par(mfrow = c(1,2))
plot(full_log_regression, which=1, main="prelim model", pch=20)
plot(full_log_regression, which=2, main="prelim model", pch=20)
```

regression with reduced model after stepwise backward elimination
```{r}
log_backward_step_model <- stepAIC(full_log_regression, direction = "backward")

summary(log_backward_step_model)

par(mfrow = c(1,2))
plot(log_backward_step_model, which=1, main="backward", pch=20)
plot(log_backward_step_model, which=2, main="backward", pch=20)

```


regression using stepwise elimination (both directions)
```{r}
log_both_step_model <- stepAIC(full_log_regression, direction = "both")

summary(log_both_step_model)

par(mfrow = c(1,2))
plot(log_both_step_model, which=1, main="both directions", pch=20)
plot(log_both_step_model, which=2, main="both directions", pch=20)
```


##### checking VIF of log stepwise regression models
```{r}
vif(log_backward_step_model, type = "predictor")
```

look for outliers using cooks distance
```{r}
cooks_distance <- cooks.distance(log_both_step_model)
threshold <- 4 / nrow(us_df)
influential_observations <- which(cooks_distance > threshold)

plot(log_both_step_model)
```


##### rerun regression without outliers to see if conclusions change (sensitivity analysis)

remove outliers
```{r}
keep_rows <- which(cooks_distance <= threshold)
us_df_no_outliers <- us_df[keep_rows, ]
```

stepwise regression using data with outliers removes to check sensitivity and robustness
```{r}
no_outlier_log_regression <- lm(log_mean_time ~ distance_km + I(distance_km^2) + elevation_gain_m +
                          pct_women + pct_age_35_59 + pct_age_60_plus +
                          distance_km*elevation_gain_m + distance_km*pct_women +
                          elevation_gain_m*pct_women, data = us_df_no_outliers)

outlierless_log_both_step_model <- stepAIC(no_outlier_log_regression, direction = "both")

summary(outlierless_log_both_step_model)

par(mfrow = c(1,2))
plot(outlierless_log_both_step_model, which=1, main="both directions", pch=20)
plot(outlierless_log_both_step_model, which=2, main="both directions", pch=20)
```



```{r}
plot(log_both_step_model)
```

these clusters are due to the most common distances 50k, 50mi, 100k, and 100mi


deciding to use the outlier-free model


vif analysis
```{r}
vif(outlierless_log_both_step_model, type = "predictor")
```



#### making scatterplots to put on the poster to show distributions


scatterplot of distance and mean time (with outliers)
```{r}
ggplot(us_df, aes(x = distance_km, y = mean_time_hrs)) +
  geom_point(alpha = 0.6, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "#f1e60e") +
  labs(
    x = "Race Distance (km)",
    y = "Mean Finish Time (hrs)",
    title = "Race Distance Vs Mean Finish Time"
  ) +
  theme_minimal(base_size = 15)
```



first scatterplot of mean time and distance with outliers removed
```{r}
ggplot(us_df_no_outliers, aes(x = distance_km, y = mean_time_hrs)) +
  geom_point(alpha = 0.6, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "#f1e60e") +
  labs(
    x = "Race Distance (km)",
    y = "Mean Finish Time (hrs)",
    title = "Race Distance Vs Mean Finish Time"
  ) +
  theme_minimal(base_size = 15)
```




second scatterplot of mean time and elevation gain (with outliers)
```{r}
ggplot(us_df, aes(x = elevation_gain_m, y = mean_time_hrs)) +
  geom_point(alpha = 0.6, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "#f1e60e") +
  labs(
    x = "Elevation Gain (m)",
    y = "Mean Finish Time (hrs)",
    title = "Elevation Gain Vs Mean Finish Time"
  ) +
  theme_minimal(base_size = 15)
```


second scatterplot of mean time and elevation gain with outliers removed
```{r}
ggplot(us_df_no_outliers, aes(x = elevation_gain_m, y = mean_time_hrs)) +
  geom_point(alpha = 0.6, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "#f1e60e") +
  labs(
    x = "Elevation Gain (m)",
    y = "Mean Finish Time (hrs)",
    title = "Elevation Gain Vs Mean Finish Time"
  ) +
  theme_minimal(base_size = 15)
```







